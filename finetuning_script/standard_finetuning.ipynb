{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix, classification_report, balanced_accuracy_score, accuracy_score\n",
    "from datasets import Dataset, DatasetDict\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Model and Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'meta-llama/Meta-Llama-3-8B'\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change between augmented dataset and Non-augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_folder = '../standard_finetuned_models/'\n",
    "predictions_folder = '../predictions_csv/'\n",
    "\n",
    "augmented_dataset = 0\n",
    "\n",
    "if augmented_dataset:   \n",
    "    output_dir = f'{models_folder}outputmodel_{model_name.split(\"/\")[-1]}_augmented_dataset_{epochs}_epochs'\n",
    "    predictions_csv_output = f'{predictions_folder}outputmodel_{model_name.split(\"/\")[-1]}_augmented_dataset_{epochs}_epochs.csv'\n",
    "else:\n",
    "    output_dir = f'{models_folder}outputmodel_{model_name.split(\"/\")[-1]}_{epochs}_epochs'\n",
    "    predictions_csv_output = f'{predictions_folder}outputmodel_{model_name.split(\"/\")[-1]}_{epochs}_epochs.csv'\n",
    "\n",
    "#Token Max length\n",
    "MAX_LEN = 512\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train = pd.read_csv('../dataset_splits/train_dataset.csv')\n",
    "df_val = pd.read_csv('../dataset_splits/val_dataset.csv')    \n",
    "df_test = pd.read_csv('../dataset_splits/test_dataset.csv')\n",
    "\n",
    "if augmented_dataset:\n",
    "    df_temp = pd.read_csv('../generated_datasets/merged_dataset.csv')\n",
    "    df_train = pd.concat([df_train, df_temp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prepare Datasets for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = Dataset.from_pandas(df_train)\n",
    "dataset_val = Dataset.from_pandas(df_val)\n",
    "dataset_test = Dataset.from_pandas(df_test)\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'train': dataset_train,\n",
    "    'val': dataset_val,\n",
    "    'test': dataset_test\n",
    "})\n",
    "\n",
    "class_counts = df_train['Memorable'].value_counts(normalize=True)\n",
    "class_weights = torch.tensor((1 / class_counts).tolist(), dtype=torch.float32)\n",
    "class_weights /= class_weights.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=8,\n",
    "    target_modules=['q_proj', 'k_proj', 'v_proj', 'o_proj'],\n",
    "    lora_dropout=0.05,\n",
    "    bias='none',\n",
    "    task_type='SEQ_CLS'\n",
    ")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=quantization_config,\n",
    "    num_labels=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the tokenizer and eos and pad tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Tokenize and Process Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_function(examples):\n",
    "    return tokenizer(examples['Quote'], truncation=True, max_length=MAX_LEN)\n",
    "\n",
    "tokenized_datasets = dataset.map(preprocessing_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.rename_column('Memorable', 'label')\n",
    "tokenized_datasets.set_format('torch')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Define Custom Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, class_weights=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.class_weights = class_weights.to(self.args.device) if class_weights is not None else None\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop('labels').long()\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits')\n",
    "        loss = F.cross_entropy(logits, labels, weight=self.class_weights) if self.class_weights is not None else F.cross_entropy(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=epochs,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    logging_steps = 100\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['val'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=collate_fn,\n",
    "    class_weights=class_weights\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "train_result = trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation on test set\n",
    "trainer.evaluate(eval_dataset=tokenized_datasets['test'])\n",
    "\n",
    "# Make predictions on the test set\n",
    "def make_predictions(trainer, df_test):\n",
    "    sentences = df_test['Quote'].tolist()\n",
    "    batch_size = 32  \n",
    "    all_outputs = []\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch_sentences = sentences[i:i + batch_size]\n",
    "        inputs = tokenizer(batch_sentences, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "        inputs = {k: v.to(trainer.args.device) for k, v in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = trainer.model(**inputs)\n",
    "            all_outputs.append(outputs['logits'])\n",
    "    final_outputs = torch.cat(all_outputs, dim=0)\n",
    "    df_test['predictions'] = final_outputs.argmax(axis=1).cpu().numpy()\n",
    "    df_test.to_csv(predictions_csv_output, index=False)\n",
    "    \n",
    "make_predictions(trainer, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance_metrics(df_test):\n",
    "    y_true = df_test['Memorable']\n",
    "    y_pred = df_test['predictions']\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print('\\nClassification Report:')\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print('Balanced Accuracy Score:', balanced_accuracy_score(y_true, y_pred))\n",
    "    print('Accuracy Score:', accuracy_score(y_true, y_pred))\n",
    "\n",
    "get_performance_metrics(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetune_llama3_unsloth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
