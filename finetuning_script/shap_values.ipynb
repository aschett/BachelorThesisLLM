{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import shap\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'meta-llama/Meta-Llama-3-8B'\n",
    "adapters = '../standard_finetuned_models/outputmodel_Meta-Llama-3-8B_5_epochs'\n",
    "test_data_path = '../dataset_splits/test_dataset.csv'\n",
    "already_evaluated = 1\n",
    "df_test = pd.read_csv(test_data_path)\n",
    "shap_evaluation_path = '../saved_shap_values/Meta-Llama-3-8B_5_epochs_shap_values.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the POS Tag used later for shapley values\n",
    "\n",
    "* ADJ = Adjective\n",
    "* NOUN = Noun\n",
    "* VERB = Verb\n",
    "* ADV = Adverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_pos = 'ADJ'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=quantization_config,\n",
    "    num_labels=2\n",
    ")\n",
    "peft_model = PeftModel.from_pretrained(model, adapters)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.use_cache = False\n",
    "peft_model.config.pad_token_id = tokenizer.pad_token_id\n",
    "peft_model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_predict(texts):\n",
    "    if isinstance(texts, np.ndarray):\n",
    "        texts = texts.tolist()\n",
    "    elif isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "\n",
    "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(peft_model.device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = peft_model(**inputs)\n",
    "    \n",
    "    return outputs.logits.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if already_evaluated:\n",
    "    with open(shap_evaluation_path, \"rb\") as f:\n",
    "        all_shap_values = pickle.load(f)\n",
    "\n",
    "else:\n",
    "    masker = shap.maskers.Text(tokenizer)\n",
    "    explainer = shap.Explainer(shap_predict, masker)\n",
    "\n",
    "    batch_size = 10\n",
    "    num_samples = len(df_test['Quote'])\n",
    "    all_shap_values = []\n",
    "\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch_sentences = df_test['Quote'].tolist()[i:i + batch_size]\n",
    "        \n",
    "        shap_values = explainer(batch_sentences)\n",
    "        all_shap_values.extend(shap_values)\n",
    "\n",
    "    with open(shap_evaluation_path, \"wb\") as f:\n",
    "        pickle.dump(all_shap_values, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code filter by Spacey and remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "token_influence_class_0 = defaultdict(list)\n",
    "token_influence_class_1 = defaultdict(list)\n",
    "\n",
    "stopwords = {\"'d\", \"'s\", \"'ll\", \"'m\", \"'re\", \"n't\", \"the\", \"a\", \"an\"}\n",
    "\n",
    "def filter_by_pos(token, pos_tags=[selected_pos]):\n",
    "    token = token.strip().lower()\n",
    "    if token in stopwords or not token.isalpha():\n",
    "        return False\n",
    "    doc = nlp(token)\n",
    "    return len(doc) > 0 and doc[0].pos_ in pos_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and filter the Shap values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample_shap_values in all_shap_values:\n",
    "    shap_tokens = sample_shap_values.data\n",
    "    tokens = tokenizer.convert_ids_to_tokens(shap_tokens) if isinstance(shap_tokens[0], int) else shap_tokens\n",
    "\n",
    "    for token_idx, token in enumerate(tokens):\n",
    "        token = token.strip().lower()\n",
    "        \n",
    "        shap_value_class_0 = sample_shap_values.values[token_idx, 0]  # SHAP value for class 0\n",
    "        shap_value_class_1 = sample_shap_values.values[token_idx, 1]  # SHAP value for class 1\n",
    "\n",
    "        if filter_by_pos(token):\n",
    "            token_influence_class_0[token].append(shap_value_class_0)\n",
    "            token_influence_class_1[token].append(shap_value_class_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the mean and median influences for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean influences\n",
    "mean_influence_class_0 = {token: np.mean(influences) for token, influences in token_influence_class_0.items()}\n",
    "mean_influence_class_1 = {token: np.mean(influences) for token, influences in token_influence_class_1.items()}\n",
    "\n",
    "# Median infleunces\n",
    "median_influence_class_0 = {token: np.median(influences) for token, influences in token_influence_class_0.items()}\n",
    "median_influence_class_1 = {token: np.median(influences) for token, influences in token_influence_class_1.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting for class Memorable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_influence_class_1_mean = {token: influence for token, influence in mean_influence_class_1.items() if influence > 0}\n",
    "negative_influence_class_1_mean = {token: influence for token, influence in mean_influence_class_1.items() if influence < 0}\n",
    "\n",
    "sorted_positive_influence_class_1_mean = sorted(positive_influence_class_1_mean.items(), key=lambda x: abs(x[1]), reverse=True)[:10]\n",
    "sorted_negative_influence_class_1_mean = sorted(negative_influence_class_1_mean.items(), key=lambda x: abs(x[1]), reverse=True)[:10]\n",
    "\n",
    "positive_influence_class_1_median = {token: influence for token, influence in median_influence_class_1.items() if influence > 0}\n",
    "negative_influence_class_1_median = {token: influence for token, influence in median_influence_class_1.items() if influence < 0}\n",
    "\n",
    "sorted_positive_influence_class_1_median = sorted(positive_influence_class_1_median.items(), key=lambda x: abs(x[1]), reverse=True)[:10]\n",
    "sorted_negative_influence_class_1_median = sorted(negative_influence_class_1_median.items(), key=lambda x: abs(x[1]), reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting for class Non-memorable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_influence_class_0_mean = {token: influence for token, influence in mean_influence_class_0.items() if influence > 0}\n",
    "negative_influence_class_0_mean = {token: influence for token, influence in mean_influence_class_0.items() if influence < 0}\n",
    "\n",
    "sorted_positive_influence_class_0_mean = sorted(positive_influence_class_0_mean.items(), key=lambda x: abs(x[1]), reverse=True)[:10]\n",
    "sorted_negative_influence_class_0_mean = sorted(negative_influence_class_0_mean.items(), key=lambda x: abs(x[1]), reverse=True)[:10]\n",
    "\n",
    "positive_influence_class_0_median = {token: influence for token, influence in median_influence_class_0.items() if influence > 0}\n",
    "negative_influence_class_0_median = {token: influence for token, influence in median_influence_class_0.items() if influence < 0}\n",
    "\n",
    "sorted_positive_influence_class_0_median = sorted(positive_influence_class_0_median.items(), key=lambda x: abs(x[1]), reverse=True)[:10]\n",
    "sorted_negative_influence_class_0_median = sorted(negative_influence_class_0_median.items(), key=lambda x: abs(x[1]), reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print values memorable class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 10 positive influence tokens for memorable - Mean:\", sorted_positive_influence_class_1_mean)\n",
    "print(\"Top 10 negative influence tokens for memorable - Mean:\", sorted_negative_influence_class_1_mean)\n",
    "print(\"Top 10 positive influence tokens for memorable - Median:\", sorted_positive_influence_class_1_median)\n",
    "print(\"Top 10 negative influence tokens for memorable - Median:\", sorted_negative_influence_class_1_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print values Non-memorable class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 10 positive influence tokens for non-memroable - Mean:\", sorted_positive_influence_class_0_mean)\n",
    "print(\"Top 10 negative influence tokens for non-memroable - Mean:\", sorted_negative_influence_class_0_mean)\n",
    "print(\"Top 10 positive influence tokens for non-memroable - Median:\", sorted_positive_influence_class_0_median)\n",
    "print(\"Top 10 negative influence tokens for non-memroable - Median:\", sorted_negative_influence_class_0_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot for memorable class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.suptitle(\"Memorable Class - Mean\", fontsize=16)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.barh([token for token, _ in sorted_positive_influence_class_1_mean], \n",
    "         [influence for _, influence in sorted_positive_influence_class_1_mean], \n",
    "         color=\"forestgreen\")\n",
    "plt.xlabel(\"Mean SHAP Influence\")\n",
    "plt.title(\"Top tokens positive influence\")\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh([token for token, _ in sorted_negative_influence_class_1_mean], \n",
    "         [influence for _, influence in sorted_negative_influence_class_1_mean], \n",
    "         color=\"darkred\")\n",
    "plt.xlabel(\"Mean SHAP Influence\")\n",
    "plt.title(\"Top tokens negative influence\")\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig('../figures/memorable_mean_shap.png')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.suptitle(\"Memorable Class - Median\", fontsize=16)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.barh([token for token, _ in sorted_positive_influence_class_1_median], \n",
    "         [influence for _, influence in sorted_positive_influence_class_1_median], \n",
    "         color=\"forestgreen\")\n",
    "plt.xlabel(\"Median SHAP Influence\")\n",
    "plt.title(\"Top tokens positive influence\")\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh([token for token, _ in sorted_negative_influence_class_1_median], \n",
    "         [influence for _, influence in sorted_negative_influence_class_1_median], \n",
    "         color=\"darkred\")\n",
    "plt.xlabel(\"Median SHAP Influence\")\n",
    "plt.title(\"Top tokens negative influence\")\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/memorable_median_shap.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot for non-memorable Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.suptitle(\"Non-memorable Class - Mean \", fontsize=16)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.barh([token for token, _ in sorted_positive_influence_class_0_mean], \n",
    "         [influence for _, influence in sorted_positive_influence_class_0_mean], \n",
    "         color=\"forestgreen\")\n",
    "plt.xlabel(\"Mean SHAP Influence\")\n",
    "plt.title(\"Top tokens positive influence\")\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh([token for token, _ in sorted_negative_influence_class_0_mean], \n",
    "         [influence for _, influence in sorted_negative_influence_class_0_mean], \n",
    "         color=\"darkred\")\n",
    "plt.xlabel(\"Mean SHAP Influence\")\n",
    "plt.title(\"Top tokens negative influence\")\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig('../figures/non_memorable_mean_shap.png')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.suptitle(\"Non-emorable Class - Median\", fontsize=16)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.barh([token for token, _ in sorted_positive_influence_class_0_median], \n",
    "         [influence for _, influence in sorted_positive_influence_class_0_median], \n",
    "         color=\"forestgreen\")\n",
    "plt.xlabel(\"Median SHAP Influence\")\n",
    "plt.title(\"Top tokens positive influence\")\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh([token for token, _ in sorted_negative_influence_class_0_median], \n",
    "         [influence for _, influence in sorted_negative_influence_class_0_median], \n",
    "         color=\"darkred\")\n",
    "plt.xlabel(\"Median SHAP Influence\")\n",
    "plt.title(\"Top tokens negative influence\")\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/non_memorable_median_shap.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetune_llama3_unsloth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
